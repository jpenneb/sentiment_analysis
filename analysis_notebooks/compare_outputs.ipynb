{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: Amenity output is ground truth\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_in_files(encoder_model, ticker):\n",
    "\n",
    "    folder_path = '/Users/jarrettpennebacker/repos/sentiment_analysis/outputs/'\n",
    "    files = glob.glob(f'{folder_path}{encoder_model}_fine_tuned_on_margin_{ticker}_*.csv')\n",
    "    \n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True),  pd.read_csv(\"amenity_extractions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date_column_in_df(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['date'] = df['date'].dt.date\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_columns_for_comparison(encoder_df, amenity_df):\n",
    "    encoder_df['sentiment'] = encoder_df['sentiment'].replace({'LABEL_1': 'pos', 'LABEL_2': 'neg', 'LABEL_0': 'neutral'})\n",
    "    amenity_df = amenity_df.rename(columns={'Financial Events Publication Date': 'date', 'Financial Events Polarity': 'sentiment', 'Financial Events Sentence': 'text'})\n",
    "    return encoder_df, amenity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_out_neutral(df):\n",
    "    return df[~df['sentiment'].isin(['neutral'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_and_filter(df, by):\n",
    "    return df.sort_values(by=by, ascending=False)[by].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_date_range(df1, df2):\n",
    "    df1['date'] = pd.to_datetime(df1['date'])\n",
    "    df2['date'] = pd.to_datetime(df2['date'])\n",
    "\n",
    "    # Limit comparison to only days of \"smallest\" dataset\n",
    "    start_date = max(df1['date'].min(), df2['date'].min())\n",
    "    end_date = min(df1['date'].max(), df2['date'].max())\n",
    "\n",
    "    return df1[(df1['date'] >= start_date) & (df1['date'] <= end_date)], df2[(df2['date'] >= start_date) & (df2['date'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_metrics(encoder_df_for_comparison, amenity_df_for_comparison):\n",
    "    # Initialize TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # You might want to combine the texts from both dataframes to ensure the vectorizer learns the full vocabulary\n",
    "    all_texts = pd.concat([encoder_df_for_comparison['text'], amenity_df_for_comparison['text']]).unique()\n",
    "    vectorizer.fit(all_texts)\n",
    "\n",
    "    # Placeholder for matches\n",
    "    matches = []\n",
    "\n",
    "    # Iterate over rows in encoder_df_for_comparison\n",
    "    for index1, row1 in encoder_df_for_comparison.iterrows():\n",
    "        # Find rows in amenity_df_for_comparison with the same date (and possibly sentiment)\n",
    "        same_date_df = amenity_df_for_comparison[amenity_df_for_comparison['date'] == row1['date']]\n",
    "        \n",
    "        # Vectorize texts for comparison\n",
    "        text1_vec = vectorizer.transform([row1['text']])\n",
    "        \n",
    "        for index2, row2 in same_date_df.iterrows():\n",
    "            text2_vec = vectorizer.transform([row2['text']])\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            sim_score = cosine_similarity(text1_vec, text2_vec)[0][0]\n",
    "            \n",
    "            # Consider texts with cosine similarity above a certain threshold as matches\n",
    "            if sim_score >= 0.7:  # Threshold of 0.8 is just an example; adjust based on your requirements\n",
    "                matches.append((index1, index2, sim_score, row1['text'], row2['text'], row1['sentiment'], row2['sentiment']))\n",
    "\n",
    "    # Convert matches to a DataFrame for easier analysis\n",
    "    matches_df = pd.DataFrame(matches, columns=['Index_df1', 'Index_df2', 'Cosine_Similarity', 'Text_df1', 'Text_df2', 'Sentiment_df1', 'Sentiment_df2'])\n",
    "\n",
    "    # Identifying (exact matches and) sentiment disagreements\n",
    "    # exact_matches = matches_df[matches_df['Cosine_Similarity'] == 1]\n",
    "    sentiment_disagreements = matches_df[(matches_df['Cosine_Similarity'] >= 0.7) & (matches_df['Sentiment_df1'] != matches_df['Sentiment_df2'])]\n",
    "\n",
    "    # Assuming encoder_df_for_comparison is df1 and amenity_df_for_comparison is df2\n",
    "    # Mark entries in both dataframes as matched based on cosine similarity comparisons\n",
    "    # Assuming matches_df contains columns ['Index_df1', 'Index_df2'] referring to original dataframe indices\n",
    "    encoder_df_for_comparison['matched'] = encoder_df_for_comparison.index.isin(matches_df['Index_df1'])\n",
    "    amenity_df_for_comparison['matched'] = amenity_df_for_comparison.index.isin(matches_df['Index_df2'])\n",
    "\n",
    "    # False Positives: Entries in df1 not matched based on cosine similarity\n",
    "    fp_df1_not_in_df2 = encoder_df_for_comparison[~encoder_df_for_comparison['matched']]\n",
    "\n",
    "    # False Negatives: Entries in df2 not matched based on cosine similarity\n",
    "    fn_df2_not_in_df1 = amenity_df_for_comparison[~amenity_df_for_comparison['matched']]\n",
    "\n",
    "    # Cleanup: You might want to remove the 'matched' columns if they're no longer needed\n",
    "    encoder_df_for_comparison.drop(columns=['matched'], inplace=True)\n",
    "    amenity_df_for_comparison.drop(columns=['matched'], inplace=True)\n",
    "\n",
    "    # Now fp_df1_not_in_df2 and fn_df2_not_in_df1 hold the false positives and negatives considering semantic similarity\n",
    "\n",
    "    # Calculate Precision and Recall\n",
    "    # Precision = TP / (TP + FP)\n",
    "    # Recall = TP / (TP + FN)\n",
    "    # TP (True Positives) = len(matches_df)\n",
    "    # FP (False Positives) = len(fp_df1_not_in_df2) + len(sentiment_disagreements)\n",
    "    # FN (False Negatives) = len(fn_df2_not_in_df1)\n",
    "\n",
    "    true_positives = len(matches_df)\n",
    "    false_positives = len(fp_df1_not_in_df2) + len(sentiment_disagreements)\n",
    "    false_negatives = len(fn_df2_not_in_df1)\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "tickers = ['GPS']\n",
    "encoder_models = ['RoBERTa'] #['ALBERT', 'BERT', 'DistilBERT', 'Electra', 'FinBERT', 'RoBERTa']\n",
    "\n",
    "scores_dict = {}\n",
    "for ticker in tickers:\n",
    "    for encoder_model in encoder_models:\n",
    "        encoder_df, amenity_df = load_in_files(encoder_model, ticker)\n",
    "        encoder_df = format_date_column_in_df(encoder_df)\n",
    "        encoder_df, amenity_df = prepare_columns_for_comparison(encoder_df, amenity_df)\n",
    "        \n",
    "\n",
    "        filtered_encoder_df = filter_out_neutral(encoder_df)\n",
    "        filtered_amenity_df = filter_out_neutral(amenity_df)\n",
    "\n",
    "        filtered_sorted_encoder_df = sort_and_filter(filtered_encoder_df, ['date', 'text', 'sentiment'])\n",
    "        filtered_sorted_amenity_df = sort_and_filter(filtered_amenity_df, ['date', 'text', 'sentiment'])\n",
    "\n",
    "        filtered_sorted_date_restricted_encoder_df, filtered_sorted_date_restricted_amenity_df = restrict_date_range(filtered_sorted_encoder_df, filtered_sorted_amenity_df)\n",
    "\n",
    "        # Remove this eventually\n",
    "        pd.concat([filtered_encoder_df.sample(n=40)[['date','sentiment','text','confidence']], encoder_df.sample(n=20)[['date','sentiment','text','confidence']]], ignore_index=False).to_csv(f\"{ticker}_{encoder_model}_results_for_review.csv\", index=False)\n",
    "\n",
    "        precision, recall, f1_score = calculate_accuracy_metrics(filtered_sorted_date_restricted_encoder_df, filtered_sorted_date_restricted_amenity_df)\n",
    "        \n",
    "        scores_dict[encoder_model] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1_score\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict_for_bar_chart = copy.deepcopy(scores_dict)\n",
    "\n",
    "# Extracting model names and their scores into separate lists\n",
    "models = list(scores_dict_for_bar_chart.keys())\n",
    "precision = [scores_dict_for_bar_chart[model]['precision'] for model in models]\n",
    "recall = [scores_dict_for_bar_chart[model]['recall'] for model in models]\n",
    "f1_scores = [scores_dict_for_bar_chart[model]['f1'] for model in models]\n",
    "\n",
    "x = np.arange(len(models))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width, precision, width, label='Precision')\n",
    "rects2 = ax.bar(x, recall, width, label='Recall')\n",
    "rects3 = ax.bar(x + width, f1_scores, width, label='F1 Score')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by model and metric')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict_for_bar_chart = scores_dict\n",
    "\n",
    "# Extracting data for plotting\n",
    "labels = np.array(['Precision', 'Recall', 'F1 Score'])\n",
    "model_names = list(scores_dict_for_bar_chart.keys())\n",
    "stats = np.array([[model_scores['precision'], model_scores['recall'], model_scores['f1']] for model_scores in scores_dict_for_bar_chart.values()])\n",
    "\n",
    "# Number of variables (i.e., the three metrics)\n",
    "num_vars = len(labels)\n",
    "\n",
    "# Compute angle each bar is centered on:\n",
    "angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "\n",
    "# The radar chart requires a closed loop, so we append the start value to the end.\n",
    "stats = np.concatenate((stats, stats[:, [0]]), axis=1)\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Draw one axis per variable and add labels\n",
    "plt.xticks(angles[:-1], labels)\n",
    "\n",
    "# Draw ylabels\n",
    "ax.set_rlabel_position(30)\n",
    "plt.yticks([0.2, 0.4, 0.6, 0.8], [\"0.2\", \"0.4\", \"0.6\", \"0.8\"], color=\"grey\", size=7)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "# Plot and fill for each model\n",
    "for idx, stat in enumerate(stats):\n",
    "    ax.plot(angles, stat, label=model_names[idx])\n",
    "    ax.fill(angles, stat, alpha=0.1)\n",
    "\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"Recent Insights From Transcripts.csv\")['Financial Events Publication Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
